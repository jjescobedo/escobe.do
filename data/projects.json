[
  {
    "id": "portfolio-website",
    "name": "escobe.do",
    "date": "Summer 2025",
    "galaxyPosition": { "x": 0.35, "y": 0.45 },
    "color": "hsl(190, 100%, 70%)",
    "sun": {
      "title": "Project Core: ",
      "subtext": "An immersive, space-themed portfolio built from the ground up with vanilla JavaScript.",
      "color": "hsl(45, 100%, 75%)",
      "body": "Why build a portfolio from scratch with vanilla JS in an era of frameworks? For the challenge and for complete control. This project was a deliberate choice to dive deep into the fundamentals of web development, proving that a captivating, complex, and performant user experience doesn't require heavy libraries.\n\nThe galaxy theme is a representation of a core philosophy: a love for exploring new worlds in technology, from quantum computing to machine learning. Each project is a star system, a new frontier waiting to be discovered. The user journey begins with an aerial view of a procedurally generated galaxy. Each star system, representing a project, glows and invites exploration. A click initiates a cinematic hyperspeed transition zooming the user into the project's solar system.\tIt's there, the project's core information orbits a central star, while detailed stories and learnings are found on the surrounding planets. The entire experience is designed to be interactive and exploratory, with parallax effects on the starfield that create a convincing sense of depth and movement."
    },
    "planets": [
      {
        "name": "at-last",
        "orbitRadius": 120, "size": 15, "color": "hsl(200, 80%, 70%)",
        "title": "At Last",
        "subtext": "",
        "body": "For a long time, my portfolio was an idea stuck in limbo. I had a version from high school, it was functional, but devoid of personality or a clear theme. It didn't represent the developer I had become. The vision for something better, something more me, was there, but the path forward was hazy.\n\nThe breakthrough came from an unexpected place. While experimenting with Three.js, I built a simple nebula script that swirled and evolved based on a mathematical seed. At that moment, everything clicked. I saw the theme, the interactivity, the entire user journey laid out before me. That nebula was the spark that ignited this project, and it gave me the core concept: a personal universe to house my work.\n\nI decided to take the road less traveled and build it entirely with vanilla JavaScript. It was a challenge, but the why was finally strong enough to carry me through the how. Finishing the first complete version of escobe.do wasn't just a relief; it was a moment of immense pride. This  living project is one I am excited to continue expanding and improving."
      },
      {
        "name": "vibey-coding",
        "orbitRadius": 200, "size": 20, "color": "hsl(260, 80%, 75%)",
        "title": "Vibe-y Coding",
        "subtext": "",
        "body": "There’s a misconception that using generative AI to code is like hitting an easy button. My experience building this portfolio taught me something different.\n\nEarly on, the site was beautiful but sluggish. The procedurally generated galaxy and complex transitions were rendering, but the performance was tanking. The frames per second were terrible, and the user experience suffered. I knew I had a serious optimization challenge ahead of me.\n\nThis was the moment I started vibing. My workflow became a dynamic conversation between me, my codebase, Stack Overflow, and GPT-4. I would describe the performance bottlenecks with intense detail, and the AI would propose solutions. There was no set formula; just a fluid, back-and-forth process. I’d test a suggestion, integrate it, and then report back on the results, iterating until we found the most elegant and efficient approach.\tThe real breakthrough moment came when I was stuck on the hyperspeed transition. I was dreading the hours of complex math and debugging it would take to create that cinematic jump to lightspeed effect. On a whim, I described my vision to the AI. The solution it returned was brilliant in its simplicity: start the stars as tiny points in the center of the screen, then rapidly expand their size and trajectory until they zoomed past the viewer. I mean it's an obvious approach but sometimes you need someone to point out the obvious to you. Not just did it give me the idea, though, but the initial code it generated worked perfectly on the first try. That single interaction saved me hours, freeing me up to focus on refining the rest of the project.\n\nWhile I'm still a healthy skeptic of using AI for everything, this project proved its incredible value. It's a powerful tool for brainstorming, for generating boilerplate, and for offering a fresh perspective when you're stuck. It felt less like a tool and more like a true collaborator—one who could challenge my thinking while still handling the easy crap, letting me focus on what truly matters: building something amazing."
      }
    ]
  },
  {
    "id": "class-sync",
    "name": "ClassSync",
    "date": "2023 - 2025",
    "galaxyPosition": { "x": 0.45, "y": 0.15 },
    "color": "hsl(220, 100%, 40%)",
    "sun": {
      "title": "Project Core",
      "subtext": "",
      "color": "hsl(35, 100%, 75%)",
      "body": "The idea for ClassSync came directly from a teacher's real-world problem: managing late students without disrupting class time. Traditional attendance methods are often inefficient and inaccurate. We created ClassSync to automate this process using facial recognition ,allowing educators to focus on teaching while providing schools with reliable attendance data.\n\nThis was a highly collaborative project. Our team, composed of members with diverse and complementary skills, used Slack for constant communication. We all contributed to various aspects of the project, from design to deployment, in a fluid and dynamic workflow."
    },
    "planets": [
      {
        "name": "business-end",
        "orbitRadius": 120, "size": 20, "color": "hsl(200, 80%, 70%)",
        "title": "Business End",
        "subtext": "",
        "body": "More than just a coding project, ClassSync was a very important opportunity for me to peer into the business of technology. I was involved in every stage, from creating our logos to conducting market analysis. Initially, we targeted K-12 schools, but our research revealed a lucrative and efficient market in universities.\n\nTo better understand our users, I conducted focus groups with teachers, students, and professors. The key insight was that automated attendance software was in high demand, even in schools that didn't necessarily 'need' it. This validated our product's potential and helped shape our strategy. Stepping out of the developer role was crucial; it gave me a deeper understanding of the product, which ultimately led to a more efficient process and a higher-quality final product."
      },
      {
        "name": "front-end",
        "orbitRadius": 160, "size": 12, "color": "hsl(260, 80%, 75%)",
        "title": "Front End",
        "subtext": "",
        "body": "My work on the front end was focused on creating a seamless and intuitive user experience. Before writing a single line of code, I meticulously planned the UI layout in Figma, focusing on how to best organize information for teachers. The biggest challenge was designing an interface that was both powerful and easy to navigate.\n\nThe front-end development process was a collaborative effort. The backend and I would design features together, ensuring that the UI and the server-side logic were perfectly aligned. This constant communication was essential for building a cohesive and reliable product."
      },
      {
        "name": "back-end",
        "orbitRadius": 240, "size": 28, "color": "hsl(140, 80%, 75%)",
        "title": "Back End",
        "subtext": "",
        "body": "While the backend wasn't my primary focus, I was involved in designing some of the initial API calls. From the very beginning, we knew that security would be our top priority. We were dealing with sensitive student data, and we had to earn the trust of parents and schools.\n\nOur solution was to design a system that minimized data storage. When a student's photo was taken, it was immediately processed by the neural network and then deleted from the disk. The only thing we stored was the encoded facial data, ensuring that students' privacy was protected. This security-first approach was a cornerstone of our architecture and a key selling point for the product."
      }
    ]
  },
  {
    "id": "etc-amp",
    "name": "Trading Bot",
    "date": "Summer 2025",
    "galaxyPosition": { "x": 0.65, "y": 0.55 },
    "color": "hsl(300, 100%, 70%)",
    "sun": {
      "title": "Project Core",
      "subtext": "A profitable algorithmic trading bot from scratch using only pure Python",
      "color": "hsl(300, 100%, 90%)",
      "body": "During a one-day electronic trading competition at Jane Street's AMP, my teammate and I were tasked with a single objective: build a trading bot from scratch to achieve the highest possible profit and loss (P/L). We were given access to a simulated market stream through an Ubuntu server and had to write our entire algorithm in pure Python, with no external libraries allowed. I took the lead on development, rapidly prototyping and bouncing strategic ideas off my teammate in a fast-paced, high-stakes environment."
    },
    "planets": [
      {
        "name": "testing-testing-more-testing",
        "orbitRadius": 300, "size": 30, "color": "hsl(140, 100%, 75%)",
        "title": "Testing, Testing, More Testing",
        "subtext": "",
        "body": "In the world of automated trading, a single bug can be the difference between profit and ruin. This competition was a crash course in the importance of rigorous, relentless testing. The competition server provided different testing rounds that simulated various market conditions, and we used every second we could to put our bot through its paces.\n\nThe aha! moment came when we noticed a bizarre inconsistency in our P/L data. We were making money when our strategy indicated we should be losing it, and vice versa. It was a clear sign that something was fundamentally wrong. After a frantic debugging session, we pinpointed the issue: our thresholds for buying and selling were flawed. We promptly fixed the logic, but the experience was a stark reminder that in a live environment, you don't get second chances. That day taught me to test not just for what you expect, but for every possible edge case you can imagine."
      },
      {
        "name": "minimum-viable-profit",
        "orbitRadius": 400, "size": 15, "color": "hsl(540, 100%, 75%)",
        "title": "Minimum Viable Profit",
        "subtext": "",
        "body": "We started the day with a grand, convoluted strategy. The plan was to use complex purchase combinations in smaller stocks to manipulate the prices of more expensive ones, minimizing our risk. It was theoretically brilliant, but in practice, it was taking far too long to implement. The competition was live, the clock was ticking, and we were bleeding points while stuck in strategic analysis.\n\nThe turning point came when a program director, Sasha, came by. He gave us a crucial piece of advice: get something in production now. Build a simple, conservative bot that guarantees a small, steady income while we figure out the master plan.\n\nWe took his advice to heart. We quickly coded a dead-simple algorithm: it calculated the average price of each stock and placed buy/sell orders at a conservative $100 threshold above or below that average. It wasn't flashy, but it worked. A slow but steady stream of income started trickling in.\tWe soon realized this temporary bot had more potential than our original complex idea. Instead of building a new strategy, we focused on optimizing the simple one, tweaking the thresholds and logic to maximize its returns. We completely abandoned our initial plan. The biggest lesson of the day was the power of a Minimum Viable Product. Sometimes, the simplest solution that gets the job done is not just a starting point—it's the best path forward."
      }
    ]
  },
  {
    "id": "alzheimers-detector",
    "name": "Alzheimers Detector",
    "date": "Summer 2024",
    "galaxyPosition": { "x": 0.2, "y": 0.75 },
    "color": "hsl(350, 100%, 70%)",
    "sun": {
      "title": "Project Core",
      "subtext": "An advanced diagnostic tool developed at Carnegie Mellon's Artificial Intelligence Scholars program that leverages a dual-model machine learning approach to predict dementia levels",
      "color": "hsl(350, 100%, 90%)",
      "body": "This project was born from a challenge posed by the CMU program, providing a perfect opportunity to apply and showcase the machine learning skills we had acquired. The goal was to build a functional, accurate tool that could contribute to the future of healthcare diagnostics.\n\nOur approach was a unique fusion of two distinct machine learning models. We used a LightGBM model to analyze tabular metadata from a Kaggle dataset (patient age, cognitive scores, etc.) and a TensorFlow-based ResNet model to perform deep learning analysis on formatted MRI brain scan images. Each model independently generated a probability of dementia. We then developed a custom weighting system to combine these probabilities, creating a single, more accurate final prediction."
    },
    "planets": [
      {
        "name": "one-of-the-classic-blunders",
        "orbitRadius": 270, "size": 24, "color": "hsl(500, 80%, 50%)",
        "title": "One of the Classic Blunders",
        "subtext": "",
        "body": "In machine learning, it’s easy to be fooled by a model that seems to work. We learned this the hard way. Our architecture was designed to feed patient metadata into our LightGBM model and MRI images into our ResNet model. However, in a critical oversight, we accidentally trained the LightGBM model—a tool designed for tabular data—on our processed image data.\n\nThe worst part is that it worked. The validation data was returning decent results, so the fundamental flaw went unnoticed. It wasn't until the day before our final presentation to the Carnegie Mellon computer science faculty that the bug was caught. During a peer code review, a classmate pointed out the error in our data pipeline.\tPanic set in. We were about to present a model that was, technically and theoretically, completely wrong. The final 24 hours were a frantic, focused scramble. Our team came together, re-architected the data flow, retrained the models correctly, and completely rebuilt our demo. The experience taught us a crucial lesson: you must deeply understand the frameworks you're using. Knowing their strengths, weaknesses, and intended use cases is the only way to ensure your final product is not just functional, but correct."
      },
      {
        "name": "blunder-to-breakthrough",
        "orbitRadius": 170, "size": 28, "color": "hsl(320, 80%, 65%)",
        "title": "Blunder to Breakthrough",
        "subtext": "",
        "body": "The final hours before the presentation were the culmination of the entire program. After identifying and fixing our original blunder, we were running on adrenaline. The breakthrough came when we finally got the two models speaking the same language. We successfully trained the LightGBM model on the correct metadata and, after a series of frantic tests, found the perfect weighting formula to combine its predictions with the ResNet image analysis.\n\nThe result was staggering. Our newly architected model achieved an accuracy of over 98%. The feeling in the room was pure relief and exhilaration, the incredible fruition of hard work born from a high-stakes crisis. We had not only fixed our mistake but had also gained a much deeper understanding of our project in the process.\n\nArmed with this newfound confidence and a model that exceeded our expectations, we nailed the presentation. We presented a compelling demo for the future of healthcare, showcasing a powerful and efficient diagnostic tool to the Carnegie Mellon faculty."
      }
    ]
  },
  {
    "id": "skin-safe",
    "name": "SkinSafe",
    "date": "Fall 2024",
    "galaxyPosition": { "x": 0.85, "y": 0.35 },
    "color": "hsl(400, 100%, 70%)",
    "sun": {
      "title": "Project Core",
      "subtext": "A mobile application developed for the Congressional App Challenge, designed for the early detection of skin cancer using a dual-model machine learning approach on phone camera images and user-provided metadata",
      "color": "hsl(400, 100%, 90%)",
      "body": "Inspired by the potential of machine learning in healthcare discovered during the Alzheimer's detector project, SkinSafe was created to make early skin cancer detection more accessible. The goal was to put a powerful diagnostic tool directly into the hands of users, empowering them to take control of their health.\n\nSkinSafe uses a hybrid machine learning model similar to the one developed for the Alzheimer's project. A LightGBM model analyzes user-provided metadata, while a ResNet model, trained on a diverse dataset of skin lesion images, analyzes photos taken with the user's phone camera. The mobile app, built with React Native and Expo, provides a user-friendly interface for capturing images and inputting data."
    },
    "planets": [
      {
        "name": "transition-to-mobile",
        "orbitRadius": 160, "size": 24, "color": "hsl(200, 80%, 70%)",
        "title": "Transition to Mobile",
        "subtext": "",
        "body": "Taking a complex machine learning model and making it work on a mobile device is a challenge. The SkinSafe project was my first real dive into mobile development, and it was a steep learning curve. The biggest hurdle was accounting for the variability of phone cameras. Unlike the clean, consistent data from MRI machines, phone camera images can be affected by lighting, focus, and a dozen other factors. This required a robust image pre-processing pipeline to normalize the data before feeding it into the model.\n\nWhile my teammate handled the bureaucratic aspects of the Congressional App Challenge submission, I was the primary developer. This meant I was responsible for everything from the UI/UX design to the backend model integration. It was a lot to manage, but it was also an incredible learning experience that gave me a holistic understanding of the mobile development lifecycle."
      },
      {
        "name": "for-the-love-of-the-game",
        "orbitRadius": 320, "size": 18, "color": "hsl(100, 80%, 50%)",
        "title": "For the Love of the Game",
        "subtext": "",
        "body": "The Congressional App Challenge was a rollercoaster. We poured countless hours into building SkinSafe, and we were proud of what we had created. So, when the results came in and we learned we hadn't placed, it was a tough pill to swallow.\n\nFor a moment, we were tilted. But after the initial disappointment wore off, we had a conversation. We talked about why we started the project in the first place: not to win an award, but to build something meaningful that could potentially help people. And in that, we had succeeded.\n\nWe decided to keep working on the project, driven by a shared motivation. The experience taught me a valuable lesson: external validation is nice, but the real prize is the knowledge you gain and the pride you take in your work. That's a win no judge can take away from you."
      }
    ]
  },
  {
    "id": "cayley-table",
    "name": "Cayley Table Visualizer",
    "date": "Summer 2023",
    "galaxyPosition": { "x": 0.95, "y": 0.75 },
    "color": "hsl(500, 100%, 70%)",
    "sun": {
      "title": "Project Core",
      "subtext": "A terminal-based Python application developed at Carnegie Mellon's Computer Science Scholars program to compute and visualize Cayley tables for symmetric groups",
      "color": "hsl(500, 100%, 90%)",
      "body": "The project began as a pure intellectual challenge: could we build a tool to visualize a complex concept from abstract algebra? The core of the project wasn't just about displaying the table, but about wrestling with the enormous optimization problems that arise. As the input number increases, the size of a symmetric group's Cayley table grows factorially (n!), leading to a massive number of calculations and a fascinating performance puzzle.\n\nThe application was built entirely in Python and operates within the command line. A user inputs an integer 'n', and the program calculates all the permutations for the symmetric group Sn, computes the group operations, and then neatly visualizes the resulting Cayley table in the terminal."
    },
    "planets": [
      {
        "name": "math-in-programming",
        "orbitRadius": 160, "size": 34, "color": "hsl(200, 80%, 70%)",
        "title": "Math in Programming?",
        "subtext": "",
        "body": "I used to think of math and programming as separate worlds. Math was the abstract, theoretical stuff, and programming was the practical, hands-on building. This project was a wake-up call. I initially took it on simply because it was the toughest challenge offered to us, and we were up for it.\n\nAs we dove deeper, I had a slow-dawning, ironic realization: this entire project was math. We weren't just writing code; we were implementing abstract algebra. Every function, every loop, was a direct translation of a mathematical concept. The challenge wasn't just getting the code to run, but understanding the group theory behind it. This project fundamentally shifted my perspective, closing the gap between theory and practice. It taught me that computer science isn’t just about building things; it’s about understanding the elegant, mathematical structures that make it all possible."
      },
      {
        "name": "my-first-big-o-n-moment",
        "orbitRadius": 400, "size": 15, "color": "hsl(260, 80%, 75%)",
        "title": "My First O(n!) Moment",
        "subtext": "",
        "body": "Our first version of the visualizer worked beautifully... for small numbers. When a user inputted 4, it was snappy. At 5, it was decent. At 6, you could feel the strain. And at 7? The program would hang, chugging through the 5,040 permutations and the 25,401 calculations needed to fill the table. Our algorithm's performance fell right off a cliff with higher values.\n\nIt was a humbling and hilarious lesson in computational complexity. Our initial, brute-force approach was simply no match for the beast that is factorial growth. This speedbump forced us to go back to the drawing board and think critically about optimization. We had to analyze every part of our code, identify bottlenecks, and explore entirely different approaches to generating permutations and calculating the group operations. It was a practical, painful, and incredibly valuable lesson. I now have a deep appreciation for algorithmic efficiency and the importance of thinking about scalability before your program grinds to a halt."
      }
    ]
  },
  {
    "id": "wordle-ai",
    "name": "AI Wordle Solver",
    "date": "Summer 2025",
    "galaxyPosition": { "x": 0.55, "y": 0.95 },
    "color": "hsl(740, 100%, 70%)",
    "sun": {
      "title": "Project Core",
      "subtext": "A highly optimized, terminal-based Wordle game and AI solver developed at Jane Street AMP that uses a sophisticated scoring algorithm to suggest the best possible guess",
      "color": "hsl(740, 100%, 90%)",
      "body": "The goal was to move beyond just playing the game and tackle the core strategic challenge: creating the most efficient and accurate Wordle solver possible. The project was less about the game interface and more about designing an AI that could logically deduce the best path to the solution in a minimum number of guesses.\n\nThe application is a polished terminal game built in Python, using the Colorama library to create a vibrant and user-friendly interface. The AI's logic is the star of the show. It analyzes the entire remaining word list and assigns a score to each possible guess. This score isn't just based on letter frequency; it's calculated by determining which word, on average, will eliminate the highest number of subsequent possibilities. This strategic approach ensures the AI's hints are designed to narrow the search space as efficiently as possible, almost guaranteeing a win within the six-guess limit."
    },
    "planets": [
      {
        "name": "trio-programming",
        "orbitRadius": 240, "size": 15, "color": "hsl(280, 80%, 60%)",
        "title": "Trio Programming?",
        "subtext": "",
        "body": "Pair programming is a concept I'd always heard about but never truly clicked with. At the beginning of this project, my two teammates and I tried the formal approach with one person coding with the others navigating and it felt forced and inefficient. We quickly abandoned it.\n\nBut a funny thing happened over the next few hours. As we dove into the complex logic of the solver, we organically fell into a rhythm that was, for all intents and purposes, a better version of what we'd been taught. We'd cluster around one screen, each of us voicing different ideas and potential implementations. One person would be typing, but the code itself was a fusion of all three of our thought processes. We were debating, building on each other's suggestions, and refining the logic in real-time. It wasn't pair programming; it was trio programming. This experience taught me that the best collaboration isn't about following a rigid formula, but about finding a natural, energetic flow where the team becomes more than the sum of its parts."
      },
      {
        "name": "best-program-so-far",
        "orbitRadius": 200, "size": 20, "color": "hsl(260, 80%, 65%)",
        "title": "Best Program I've Made... So Far",
        "subtext": "",
        "body": "The most difficult part of this project was the standard we held ourselves to when developing. This was the final project of the AMP program, and it felt like the culmination of everything we had learned. We had a solid strategy for the AI from the start, but the real challenge was implementing it with clean, professional, and maintainable code.\n\nThis project was a huge step up for me. The whole development process felt closer to a professional workflow than anything I'd done before. We didn't just find one solution; we explored multiple alternative approaches, benchmarked them, and optimized the most promising one. We boosted the AI's accuracy while maintaining pristine code structure and style.\n\nThe final product isn't perfect, but it's pretty darn good. More importantly, I'm incredibly proud of it. It represents a new level of quality in my work and a development process that was both challenging and deeply rewarding. It’s the kind of program I would love to build again, and for that reason, it’s the best one I’ve made... so far."
      }
    ]
  }
]